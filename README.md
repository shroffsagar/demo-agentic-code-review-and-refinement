A demo project to show agentic code review and refinement on the github PR

# Log Analyzer

A Python utility for parsing, analyzing, and extracting insights from log files generated by various systems.

## Features

- Parse log files from multiple formats automatically
- Filter log entries by level, service, time range, or custom queries
- Generate activity timelines to visualize log volume over time
- Extract common patterns and message templates
- Identify error hotspots across services
- Export analysis results to JSON for further processing

## Usage

```python
from log_analyzer import LogAnalyzer

# Create analyzer and parse logs
analyzer = LogAnalyzer()
analyzer.parse_file("application.log")

# Or parse an entire directory
analyzer.parse_folder("logs", file_pattern="*.log")

# Filter results
errors = analyzer.filter_by_level(["ERROR", "CRITICAL"])
recent = analyzer.filter_by_timerange(start_time, end_time)

# Generate insights
error_summary = analyzer.get_error_summary()
timeline = analyzer.get_activity_timeline(interval_minutes=60)
patterns = analyzer.find_patterns(min_occurrences=5)

# Export results
analyzer.export_to_json("analysis_results.json")

# Generate comprehensive report
report = analyzer.generate_report()
```

## Requirements

- Python 3.6+
- No external dependencies

## Example

Check out `example.py` for a detailed usage example:

```bash
python example.py path/to/logs
```

## Extending

You can extend the analyzer with custom log parsing patterns:

```python
# Custom regex pattern with named groups
pattern = r'(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (?P<level>\w+) \[(?P<service>\w+)\] (?P<message>.*)'
analyzer.parse_file("custom.log", custom_pattern=pattern)
```

## License

MIT 
